{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifying"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-15 02:02:58.247907: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-01-15 02:02:58.441833: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-01-15 02:02:58.441844: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-01-15 02:02:59.042471: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-01-15 02:02:59.042519: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-01-15 02:02:59.042523: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import sklearn.model_selection\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils.json_utils as jsu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Inputs & Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(jsu.read_json(\"10_X_subjects_black_clover.json\"))\n",
    "Y = np.array(jsu.read_json(\"10_Y_tokens_black_clover.json\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Separate into Train & Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x_train, x_valid, y_train, y_valid = sklearn.model_selection.train_test_split(X, Y, test_size=0.3, random_state=0)\n",
    "x_train, x_valid, y_train, y_valid = X, X, Y, Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "callback_early_stopping = keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, verbose=0, mode='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-15 02:03:02.079310: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2023-01-15 02:03:02.079324: W tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:265] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2023-01-15 02:03:02.079336: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (Homura): /proc/driver/nvidia/version does not exist\n",
      "2023-01-15 02:03:02.079468: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 3528)              162288    \n",
      "                                                                 \n",
      " leaky_re_lu (LeakyReLU)     (None, 3528)              0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 3528)              12450312  \n",
      "                                                                 \n",
      " leaky_re_lu_1 (LeakyReLU)   (None, 3528)              0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 3528)              12450312  \n",
      "                                                                 \n",
      " leaky_re_lu_2 (LeakyReLU)   (None, 3528)              0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 3528)              12450312  \n",
      "                                                                 \n",
      " leaky_re_lu_3 (LeakyReLU)   (None, 3528)              0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 3528)              12450312  \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 49,963,536\n",
      "Trainable params: 49,963,536\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = keras.models.Sequential()\n",
    "model.add(keras.Input(shape=x_train.shape[1]))\n",
    "\"\"\"\n",
    "model.add(keras.layers.core.Dense(Y.shape[1]))\n",
    "model.add(keras.layers.LeakyReLU(alpha=0.3))\n",
    "model.add(keras.layers.core.Dense(Y.shape[1]))\n",
    "model.add(keras.layers.LeakyReLU(alpha=0.3))\n",
    "model.add(keras.layers.core.Dense(Y.shape[1]))\n",
    "model.add(keras.layers.LeakyReLU(alpha=0.3))\n",
    "model.add(keras.layers.core.Dense(Y.shape[1]))\n",
    "model.add(keras.layers.LeakyReLU(alpha=0.3))\n",
    "\"\"\"\n",
    "model.add(keras.layers.core.Dense(Y.shape[1]))\n",
    "model.add(keras.layers.LeakyReLU(alpha=0.3))\n",
    "model.add(keras.layers.core.Dense(Y.shape[1]))\n",
    "model.add(keras.layers.LeakyReLU(alpha=0.3))\n",
    "model.add(keras.layers.core.Dense(Y.shape[1]))\n",
    "model.add(keras.layers.LeakyReLU(alpha=0.3))\n",
    "model.add(keras.layers.core.Dense(Y.shape[1]))\n",
    "model.add(keras.layers.LeakyReLU(alpha=0.3))\n",
    "model.add(keras.layers.core.Dense(Y.shape[1], activation='softmax'))\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adadelta\",metrics=[\"accuracy\"])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nmodel = keras.models.Sequential()\\nmodel.add(keras.Input(shape=x_train.shape[1]))\\n\\nmodel.add(keras.layers.core.Dense(Y.shape[1], activation=\\'sigmoid\\'))\\nmodel.add(keras.layers.core.Dense(Y.shape[1], activation=\\'sigmoid\\'))\\nmodel.add(keras.layers.core.Dense(Y.shape[1], activation=\\'sigmoid\\'))\\nmodel.add(keras.layers.core.Dense(Y.shape[1], activation=\\'sigmoid\\'))\\nmodel.add(keras.layers.core.Dense(Y.shape[1], activation=\\'sigmoid\\'))\\n\\nmodel.add(keras.layers.core.Dense(Y.shape[1], activation=\\'sigmoid\\'))\\nmodel.add(keras.layers.core.Dense(Y.shape[1], activation=\\'sigmoid\\'))\\nmodel.add(keras.layers.core.Dense(Y.shape[1], activation=\\'sigmoid\\'))\\nmodel.add(keras.layers.core.Dense(Y.shape[1], activation=\\'softmax\\'))\\nmodel.compile(loss=\"categorical_crossentropy\", optimizer=\"adadelta\",metrics=[\"accuracy\"])\\nprint(model.summary())\\n'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "model = keras.models.Sequential()\n",
    "model.add(keras.Input(shape=x_train.shape[1]))\n",
    "\n",
    "model.add(keras.layers.core.Dense(Y.shape[1], activation='sigmoid'))\n",
    "model.add(keras.layers.core.Dense(Y.shape[1], activation='sigmoid'))\n",
    "model.add(keras.layers.core.Dense(Y.shape[1], activation='sigmoid'))\n",
    "model.add(keras.layers.core.Dense(Y.shape[1], activation='sigmoid'))\n",
    "model.add(keras.layers.core.Dense(Y.shape[1], activation='sigmoid'))\n",
    "\n",
    "model.add(keras.layers.core.Dense(Y.shape[1], activation='sigmoid'))\n",
    "model.add(keras.layers.core.Dense(Y.shape[1], activation='sigmoid'))\n",
    "model.add(keras.layers.core.Dense(Y.shape[1], activation='sigmoid'))\n",
    "model.add(keras.layers.core.Dense(Y.shape[1], activation='softmax'))\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adadelta\",metrics=[\"accuracy\"])\n",
    "print(model.summary())\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "5989/5989 [==============================] - 2915s 487ms/step - loss: 80.7455 - accuracy: 0.0000e+00 - val_loss: 78.5074 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "5989/5989 [==============================] - 2898s 484ms/step - loss: 102.6886 - accuracy: 0.0000e+00 - val_loss: 168.7070 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/10\n",
      "5989/5989 [==============================] - 2882s 481ms/step - loss: 553.3632 - accuracy: 0.0000e+00 - val_loss: 1290.6359 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/10\n",
      "5989/5989 [==============================] - 2882s 481ms/step - loss: 3557.6804 - accuracy: 0.0000e+00 - val_loss: 7205.0151 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/10\n",
      "5989/5989 [==============================] - 2883s 481ms/step - loss: 16182.5088 - accuracy: 0.0000e+00 - val_loss: 28794.4531 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/10\n",
      "5989/5989 [==============================] - 2877s 480ms/step - loss: 55009.1367 - accuracy: 1.6697e-04 - val_loss: 91624.3594 - val_accuracy: 8.3486e-04\n",
      "Epoch 7/10\n",
      "5989/5989 [==============================] - 2868s 479ms/step - loss: 158096.6250 - accuracy: 3.3395e-04 - val_loss: 246278.0938 - val_accuracy: 1.6697e-04\n",
      "Epoch 8/10\n",
      "5989/5989 [==============================] - 2883s 481ms/step - loss: 392688.4375 - accuracy: 0.0013 - val_loss: 585494.5625 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/10\n",
      "5989/5989 [==============================] - 2856s 477ms/step - loss: 890406.0625 - accuracy: 0.0013 - val_loss: 1265559.6250 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/10\n",
      "5989/5989 [==============================] - 2864s 478ms/step - loss: 1837226.7500 - accuracy: 0.0012 - val_loss: 2520795.7500 - val_accuracy: 0.0055\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fc7e6532200>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, batch_size=1, epochs=10, validation_data=(x_valid, y_valid), verbose=1, callbacks=[callback_early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "character2index = jsu.read_json(\"10_character2index_black_clover.json\")\n",
    "index2character = jsu.read_json(\"10_index2character_black_clover.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "token2index = jsu.read_json(\"10_token2index_black_clover.json\")\n",
    "index2token = jsu.read_json(\"10_index2token_black_clover.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 34ms/step\n"
     ]
    }
   ],
   "source": [
    "hot_encoded_yuno = np.zeros((1, len(character2index)))\n",
    "hot_encoded_yuno[0][character2index['Asta']] = 1\n",
    "\n",
    "yuno = model.predict(hot_encoded_yuno)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1144, 1154, 1155, 1152, 1150, 1153, 1129, 1151, 1146, 1149, 1148,\n",
       "       1147, 1132, 1157, 1130, 1156, 1128, 1127, 1126, 1125, 1124, 1123,\n",
       "       1122, 1121, 1120, 1119, 1118, 1117, 1116, 1115, 1114, 1113, 1112,\n",
       "       1111, 1110, 1109, 1108, 1107, 1106, 1105, 1207, 1208, 1158, 1159,\n",
       "       1160, 1161, 1162, 1163, 3367, 1164, 1165, 1166, 1167, 1168, 1169,\n",
       "       1170, 1171, 1172, 1173, 1174, 1175,  623, 1176, 1177, 1178, 3049,\n",
       "       1179, 1180, 1181, 1182, 1183, 3388, 1184, 1185, 1186, 2178, 1187,\n",
       "       1188, 1189, 2549, 1190, 1191, 3214, 1192, 1193, 1194, 1195, 1196,\n",
       "       1197, 1198, 1199, 1200, 1201, 1202, 1203, 1204, 1205, 1323, 1206,\n",
       "       3527])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_tokens_indexes = np.argpartition(yuno[0], -100)[-100:]\n",
    "top_tokens_indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 \t thrust\n",
      "0.0 \t impose\n",
      "0.0 \t adamantly\n",
      "0.0 \t forest\n",
      "0.0 \t describe\n",
      "0.0 \t danger\n",
      "0.0 \t relief\n",
      "0.0 \t bind\n",
      "0.0 \t strong\n",
      "0.0 \t intent\n",
      "0.0 \t regrow\n",
      "0.0 \t birth\n",
      "0.0 \t foot\n",
      "0.0 \t enter\n",
      "0.0 \t copy\n",
      "0.0 \t tea\n",
      "0.0 \t powerfully\n",
      "0.0 \t hard\n",
      "0.0 \t beaver\n",
      "0.0 \t picture\n",
      "0.0 \t fame\n",
      "0.0 \t bike\n",
      "0.0 \t behave\n",
      "0.0 \t however\n",
      "0.0 \t gang\n",
      "0.0 \t laying\n",
      "0.0 \t victory\n",
      "0.0 \t banquet\n",
      "0.0 \t weird\n",
      "0.0 \t overhear\n",
      "0.0 \t bartender\n",
      "0.0 \t request\n",
      "0.0 \t coincidentally\n",
      "0.0 \t dimension\n",
      "0.0 \t challenge\n",
      "0.0 \t store\n",
      "0.0 \t Orsi\n",
      "0.0 \t prepared\n",
      "0.0 \t cave\n",
      "0.0 \t campfire\n",
      "0.0 \t volatile\n",
      "0.0 \t involve\n",
      "0.0 \t acceptance\n",
      "0.0 \t beak\n",
      "0.0 \t shut\n",
      "0.0 \t guard\n",
      "0.0 \t knight\n",
      "0.0 \t incident\n",
      "7.7688645e-32 \t Asta\n",
      "0.0 \t damanito\n",
      "0.0 \t counter\n",
      "0.0 \t result\n",
      "0.0 \t afterward\n",
      "0.0 \t vote\n",
      "0.0 \t innocence\n",
      "0.0 \t maximum\n",
      "0.0 \t need\n",
      "0.0 \t alive\n",
      "0.0 \t busy\n",
      "0.0 \t intercept\n",
      "0.0 \t boys\n",
      "2.6953223e-19 \t silva\n",
      "0.0 \t karen\n",
      "0.0 \t gamble\n",
      "0.0 \t sens\n",
      "2.0896612e-10 \t Noelle\n",
      "0.0 \t intense\n",
      "0.0 \t increase\n",
      "0.0 \t alone\n",
      "0.0 \t bubble\n",
      "0.0 \t kahono\n",
      "4.3500295e-18 \t ask\n",
      "0.0 \t writing\n",
      "0.0 \t please\n",
      "0.0 \t tow\n",
      "4.508428e-27 \t Finral\n",
      "0.0 \t lag\n",
      "0.0 \t growth\n",
      "0.0 \t corps\n",
      "4.4774075e-34 \t Yuno\n",
      "0.0 \t kravitz\n",
      "0.0 \t race\n",
      "0.46879065 \t Yami\n",
      "0.0 \t platform\n",
      "0.0 \t accepts\n",
      "0.0 \t mission\n",
      "0.0 \t annoy\n",
      "0.0 \t crime\n",
      "0.0 \t lot\n",
      "0.0 \t argue\n",
      "0.0 \t arrow\n",
      "0.0 \t back\n",
      "0.0 \t breakfast\n",
      "0.0 \t tire\n",
      "0.0 \t compare\n",
      "0.0 \t chef\n",
      "0.0 \t elitist\n",
      "0.5312094 \t go\n",
      "0.0 \t noble\n",
      "0.0 \t notice\n"
     ]
    }
   ],
   "source": [
    "for token_index in top_tokens_indexes:\n",
    "    print(yuno[0][token_index], '\\t', index2token[str(token_index)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0]), array([1323]))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.where(yuno == np.max(yuno))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'go'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index2token['1323']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yuno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
